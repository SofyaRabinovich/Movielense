---
title: "Capstone project"
author: "Sofya Rbinovich"
date: "16/10/2021"
output: pdf_document
---

## Used Libraries 
```{r, message=FALSE}
library(broom)
library(dslabs)
library(HistData)
library(tidyverse)
library(tidyr)
library(tidyselect)
library(tidytext)
library(dplyr)
library(gridExtra)
library(ggplot2)
library(ggpubr)
library(ggrepel)
library(ggsci)
library(ggsignif)
library(ggthemes)
library(readxl)
library(readr)
library(reshape2)
library(lpSolve)
library(lubridate)
library(caret)
library(e1071)
library(MASS)
library(purrr)
library(pdftools)
library(matrixStats)
library(rpart)
library(recosystem)
library(Rborist)
library(randomForest)
library(ggraph)
library(igraph)
```

# Introduction 
The "Movielense" project was made for the capstone project of the HarvardX: PH125.9x module. Recommedation systems are an important part of the machine learning algorithms and help to offer a suggestions for the users according their preferences and selection of movies/products. Companies such as LinkedIn, Amazon, Netflix and etc. are using recommender systems to satisfy and ease the search of their customers. 
Recommender systems are generally divided into a collaborative filtering and content-based systems. Collaborative filtering system is based on the previous selections of users, so the input will be organised as a historical data of user interaction with targets. The data is stored in the matrix where the userId is the row and the itemId is in the columns (the same as we will use in our model later in this project). On the other hand, content-based model will use other inputs to make a predictions. Additional inputs might be age, job, sex, location and other personal information information provided by the user while we was registering. 
```{r recommeder systems graph, echo = FALSE, results='hide', fig.show='hold'}
d1 <- data.frame(from = "Recommender System", to = "Content - Based")
d2 <- data.frame(from = "Recommender System", to = "Collaborative Filtering")
rbind(d1,d2)
d3 <- data.frame(from = "Collaborative Filtering", to = c("Model Based", "Memory Based"))
bind <- rbind(d1, d2, d3)
graph <- graph_from_data_frame(bind)
ggraph(graph, layout = "dendrogram", circular = FALSE) + 
  geom_edge_diagonal() +
  geom_node_point(size = 3) +
  geom_node_text(aes(label = c("Recommender System" , "Collaborative Filtering","Content-Based", "Model-Based",
                               "Memory-Based"), 
                     hjust = (c(1.3, 1.1, 1.05, -0.1, 1.1))))
  theme_void()
```

In this project we will look at the Netflix Prize open competition that was introduced on the 2nd of October 2006. The aim of the competition was to provide the best collaborative filtering algorithm to predict the user rating to the film based on the previous ratings using limited information. By the June 2007 over 20 000 teams had registered for the competition and in the September 2009 the team called  "BellKor's Pragmatic Chaos" won the prize and achieved RMSE = 0.8567. The grand prize was US$1,000,000. 

# Aims of the project 

The aim of the project is to train different linear models to achieve the most accurate RMSE result using the provided training set (edx) and test set (validation). 
Objectives: 
1. Explore the data; 
2. Look for the correlation between different parameters;
3. Preprocess the data by removing any NAs and zero variance parameters; 
4. Train different linear models and compare the RMSE results.

# Data Download 
```{r, message=FALSE}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 4.0 or later:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))


movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1) 
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1,
                                  list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)
rm(dl, ratings, movies, test_index, temp, movielens, removed)

```

# Data Exploration
Overview data
```{r overview, echo=FALSE}
edx %>%
  head() %>%
  knitr::kable()
edx %>%
  tail() %>%
  knitr::kable()
```
Now we will investigate the number of unique movies and the number of unique users 
```{r unique users and movies}
table_of_unique_movies_and_users <- data.frame(unique_users = edx %>% 
                                                 summarise(n_users = n_distinct(userId)), 
                                               unique_movies = edx %>%
                                                 summarise(n_movies = n_distinct(movieId))) %>%
  knitr::kable()
table_of_unique_movies_and_users
```
Therefore, we can conclude that the number of users is 69878 and the number of movies is 10677 in the edx dataset. 
```{r dataset summary}
knitr::kable(summary(edx))
```
From the table above we can see that the minimum rating given to a movie was 0.5, meanwhile, the highest rating given was 5.0. 
```{r distribution of ratings}
edx %>%
  ggplot(aes(rating)) + 
  geom_histogram(binwidth = 0.5, color = I('black')) +
  ggtitle("Rating Distribution") +
  labs(caption = "The minimal rating is 0.5, and the maximum is 5.0. 
       We can see that the data is skewed to the right. 
       Also, from the histogram we notice that no user gave 0.0 rating")
```
It is obvious that some people preferred one movie genre to another, therefore, it is worth to investigate the effect of the genre on the movie rating. We will look at top 20 genres in the data set.
```{r movie genres}
top_genres <- edx %>%
  group_by(genres) %>%
  summarise(count = n()) %>%
  top_n(20, count) %>%
  arrange(desc(count)) %>%
  knitr::kable()
top_genres
```
```{r genre effect by plotting averages and standard errors }
edx %>%
  group_by(genres) %>%
  summarise(n = n(), avg = mean(rating), se = sd(rating)/sqrt(n())) %>%
  filter(n >= 100000) %>%
  mutate(genres = reorder(genres, avg)) %>%
  ggplot(aes(x = genres, y = avg, ymin = avg - 2*se, ymax = avg + 2*se)) + 
  geom_point() +
  geom_errorbar() + 
  theme(axis.text.x = element_text(angle = 40, hjust = 1)) +
  ylab("Averages") + 
  ggtitle("Standard errors by genres")
```

We can see that the top genre is Drama followed by Comedy and Action. 
It is interesting to know, which movies are at the top.
```{r top movies}
top_movies <- edx %>%
  group_by(title) %>%
  summarise(rating_count = n()) %>%
  top_n(15, rating_count) %>%
  arrange(desc(rating_count)) %>%
  knitr::kable()
top_movies
```
As we established there are 10677 movies in the data set and using the logic we can say that some movies are rated watched more than others and therefore are rated more frequently. Whereas, others can be rated only few times. 
```{r ratings/movie}
edx %>% 
  dplyr::count(movieId) %>%
  ggplot(aes(n)) +
  geom_histogram(binwidth = 0.25, bins = 30, color = I('black')) +
  scale_x_log10() +
  theme_classic() +
  xlab("Number of ratings per movie") +
  ylab("Number of the movies") +
  ggtitle("Number of rating per movie") +
  labs(caption = "The distribution is almost symmetric.
  Few rating count can make the model inaccurate.
  Therefore these movies should be excluded from the list in the preprocessiing step.")
```
We can see that some movies were rated only one time, and some were rated for 
more than 10'000 time.
Now we should define which movies were rated only once in order to consider
their exclusion from the data set in the preprocessiong step.
```{r rated only once}
rated_1_time <- edx %>%
  group_by(movieId) %>%
  summarise(number_of_ratings = n()) %>%
  filter(number_of_ratings == 1) %>%
  left_join(edx, by = "movieId") %>%
  dplyr::select(title, movieId, number_of_ratings) %>%
  knitr::kable()
rated_1_time
```
There are 126 movies that are rated only once and it is 1.18% only from all
the movies.
As we defined previously there is 69878 and we can check the number of ratings 
given by them. 
```{r number of ratings by user}
edx %>%
  dplyr::count(userId) %>%
  ggplot(aes(n)) +
  geom_histogram(binwidth = 0.15, bins = 30, color = I('black')) +
  scale_x_log10() +
  theme_classic() +
  xlab("Number of ratings give by user") +
  ylab("Number of users") +
  ggtitle("Number of ratings per user") +
  labs(caption = "The graph is skewed to the right (positive).")
```
We can see that some users have rated less than 30 movies, and this will 
underestimate our models.
We also know that more recent movies are tend to be rated more frequently than 
older ones. Therefore we can convert the timestamp column of the edx data set 
into a date of the rating was given. Afterwards, we will be able to explore 
the relationship of the date and rating. 
```{r Explore the relationship of year and rating}
edx %>%
  mutate(year = year(as_datetime(timestamp))) %>%
  ggplot(aes(year)) +
  geom_histogram(binwidth = 0.15, bins = 30, color = I('black')) +
  ggtitle("Rating over time") +
  xlab("Year") +
  ylab("Rating") +
  theme_classic()
```
Looking at the graph can suggest some relationship between the time and the 
rating, however, there is no strong correlation. 

# Data Preprocessing 
First of all we should say that the data set is tidy, however, it is better to 
check if there is any NAs in the data. 
```{r check if there is any missing values, results= 'hide'}
anyNA(edx)
```
Next step would be the removal of the variance that is close to zero. 
```{r clear near 0 variance, results='hide'}
nearZeroVar(edx$rating)
```
# Methods and Analysis 
## Linear Model 
The start model assumes the same prediction for all users and movies, explaining difference by random variation. Here $\mu$ represents the "true" rating for all movies. $\epsilon$ is an independent errors sampled from the same distribution, that is centered at zero. The first equation to use will be: 
$$\hat{Y}_{u,i}=\mu + \epsilon_{u,i}$$
The $\hat{Y}$ is the predicted rating. Any additional value will increase the  root mean squared error (RMSE).
$$RMSE = \sqrt{\frac{1}{N}\sum_{u,i}(\hat{y}_{u,i}-y_{u,i})^2}$$
Therefore, we will add an additional variable $b_i$ that represents the average ranking for the movie i, improving our RMSE model: 
$$b_i = mean(\hat{Y}_{u,i}-\mu)$$
$$\hat{Y}_{u,i}=\mu+b_i+\epsilon_{u,i}$$
Knowing that some users ranked more movies than other users brings in place another bias, user-specific effect. We will call this variable $b_u$, and therefore, increase the RMSE: 
$$\hat{Y}_{u,i}=\mu+b_i+b_u+\epsilon_{u,i}$$
From the data exploration we defined that there is some effect of the time on the rating, therefore we can imply time-specific effect to the RMSE model. However, the correlation was not significant and may cause in decrease of the RMSE, so we would not use time-specific effect in our analysis. 

## Regularisation 

The linear model $\hat{Y}_{u,i}=\mu+b_i+b_u+\epsilon_{u,i}$ will provide a good estimation of ratings, however it will not penalize large estimates that come from small samples. For example, movies that were rated few times or users that gave ratings for very few movies. Not accounting this will lead to the large estimated errors. 
Therefore, the estimated value will be improved by applying the penalty term. The b's estimate now will be: 
$$\frac{1}{N}\sum_{u,i}(y_{u,i}-\mu-b_i)^2+\lambda\sum_ib_i^2$$
The $\frac{1}{N}\sum_{u,i}(y_{u,i}-\mu-b_i)^2$ is the mean square error, and the $\lambda\sum_ib_i^2$ is a penalty term. Note that when b is getting large the penalty term increases. Now we can calculate the movie-specific and the user-specific effects using regularization: 
$$\hat{b_i} = \frac{1}{\lambda + n_i}\sum^{n_i}_{u=1}(y_{u,i}-\hat{\mu})$$ 
$$\hat{b_u} = \frac{1}{\lambda + n_u}\sum^{n_u}_{i=1}(y_{u,i}-\hat{b_i}-\hat{\mu}) $$
Here $\lambda$ is a tuning parameter and we can use cross-validation to choose the minimum one that gives the most accurate RMSE.

## Matrix Factorisation 

Data can be converted into matrix to study the same rating patterns in the movies and users groups. Each user gets a row and each movie gets a column. The aim is to approximate the large matrix $R_{m\times n}$ into two smaller vectors $P_{k\times m}$ and $Q_{k\times m}$, such that : $R \approx P'Q$. $p_u$ is the u-th row of P, and $q_i$ is the v-th row of Q. Therefore, the the rating given by the user $u$ for the movie $i$ is $p_uq_i'$.This allows us to apply more variance in the original RMSE model: 
$$\hat{Y}_{u,i}=\mu+b_i+b_u+p_uq_i+\epsilon_{i,j}$$. 
We can use Singular value composition (SVD) that finds the vectors p and q that permit us to write the matrix of residuals r with m rows and n columns. By using principal components analysis (PCA), matrix factorization can capture structure in the data determined by user opinions about movies. 
For Matrix Factorisation we will user the Recosystem package. 

# Results 
First of all we will define a dataframe that will store all our RMSE values as we go along with our analysis. And we will include the desired RMSE value in it. 
```{r dataframe with results, echo=FALSE}
model_results <- data.frame(method = "Goal RMSE", 
                            RMSE = 0.8649)
```
Secondly, we should define the RMSE function to calculate it using different models. In the Machine Learning module we were using test sets and training sets. However, here we have an edx data table as the training set and a validation data table for predicted ratings. 
```{r RMSE function }
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}
```
Now we will try to predict the RMSE value using Monte Carlo simulation. Since we are not using any linear models or regulisations, the RMSE result would be the highest among all other models. 
```{r Monte Carlo simulation }
## Monte Carlo prediction 
set.seed(4321)
# Create the probability of each rating
p <- function(x, y) mean(y == x)
rating <- seq(0.5,5,0.5)
#Estimate the probability of each rating
B <- 10000
N <- 100
MS <- replicate(B, {
  X <- sample(edx$rating,N, replace = TRUE)
  sapply(rating, p, y = X)
})
probability <- sapply(1:nrow(MS), function(x) mean(MS[x,]))
#Random ratings prediction 
y_hat <- sample(rating, size = nrow(edx), 
                replace = TRUE, prob = probability)
#Store the prediction in the table 
model_results <- bind_rows(model_results, 
                           data.frame(method = "Monte Carlo simulation", 
                                      RMSE = RMSE(edx$rating, y_hat)))
```
### Naive RMSE 

Now we start to apply a simple linear model, $\hat{Y}_{u,i}=\mu + \epsilon_{u,i}$. 
```{r naive_RMSE, results='hide'}
#Find the "true" ratings for all movies, mu
mu_hat <- mean(edx$rating)
mu_hat
#Add this model to the table 
model_results <- bind_rows(model_results, 
                           data.frame(method = "Just the average", 
                           RMSE = RMSE(edx$rating, mu_hat)))
```
### Movie effect model

Now we will include movie effect ($b_i$). Firstly, we should define $b_i$ using the equation: 
$$b_i = mean(\hat{Y}_{u,i}-\mu)$$
```{r calculation of b_i}
b_i <- edx %>%
  group_by(movieId) %>%
  summarise(b_i = mean(rating - mu_hat))
head(b_i)
```
Secondly, we will calculate the $\hat{Y}_{u,i}$ using the following equation: 
$$\hat{Y}_{u,i}=\mu+b_i+\epsilon_{u,i}$$
```{r movie averages}
predicted_ratings <- mu_hat + validation %>%
  left_join(b_i, by = 'movieId') %>%
  .$b_i
```
And lastly we will calculate the RMSE and add this model to the table for comparasion
```{r RMSE with movie effect}
movie_specific_RMSE <- RMSE(validation$rating, predicted_ratings)
movie_specific_RMSE
#Add to the model table 
model_results <- bind_rows(model_results, 
                           data.frame(method = "Movie Effect Model", 
                                      RMSE = movie_specific_RMSE))
```
### User effect model 

Here we will calculate the RMSE using the user effect, $b_u$. And then using the formula, $\hat{Y}_{u,i}=\mu+b_i+b_u+\epsilon_{u,i}$, we will compute the prediction ratings. 
```{r User effect model}
b_u <- edx %>%
  left_join(b_i, by = 'movieId') %>%
  group_by(userId) %>%
  summarise(b_u = mean(rating - mu_hat - b_i))
predicted_ratings <- validation %>%
  left_join(b_i, by = 'movieId') %>%
  left_join(b_u, by = 'userId') %>%
  mutate(prediction = mu_hat + b_i + b_u) %>%
  .$prediction
user_specific_RMSE <- RMSE(validation$rating, predicted_ratings)
# Add the RMSE to the model table 
model_results <- bind_rows(model_results, 
                           data.frame(method = "Movie + User Effect Model", 
                                      RMSE = user_specific_RMSE))
```
We can observe that with that the applying $b_i$ and $b_u$ to the model improved our RMSE. However, further steps are required to reach the goal. 
```{r print model results}
knitr::kable(model_results)
```
### Regulization 

Now we should regularize movie and user effect using tuning parameter $\lambda$. We will define lambdas as following: 
```{r lambdas}
lambdas <- seq(0, 10, 0.25)
```
We can use cross-validation to estimate the best value of $\lambda$ for the most improved RMSE. For this we should define the "RMSES" function. It will take few minutes to be completed. 
```{r RMSES function}
RMSES <- sapply(lambdas, function(l){
  mu_hat <- mean(edx$rating)
  b_i <- edx %>%
    group_by(movieId) %>%
    summarise(b_i = sum(rating - mu_hat)/(n() + l))
  b_u <- edx %>%
    left_join(b_i, by = 'movieId') %>%
    group_by(userId) %>%
    summarise(b_u = sum(rating - b_i - mu_hat)/(n() + l))
  predicted_user_movie_rating <- validation %>%
    left_join(b_i, by = 'movieId') %>%
    left_join(b_u, by = 'userId') %>%
    mutate(prediction = mu_hat + b_i + b_u) %>%
    .$prediction
  return(RMSE(validation$rating, predicted_user_movie_rating))
})
```
Now we can plot lambdas over RMSES results 
```{r plot lambdas over RMSES results }
qplot(lambdas, RMSES)
```
Now we can find the value of lambda that referrers to the minimal RMSE
```{r minimum lambda}
lambda <- lambdas[which.min(RMSES)]
lambda
```
Therefore, the final model RMSE is: 
```{r final RMSE, echo=FALSE}
regularised_user_movie_specific_rmse <- min(RMSES)
regularised_user_movie_specific_rmse
```
The last step is to add our final RMSE value to the model results table
```{r final table}
model_results <- bind_rows(model_results, 
                           data.frame(method = "Regularised Movie + User Effect Model", 
                                      RMSE = regularised_user_movie_specific_rmse))
knitr::kable(model_results)
```
We can see that the final RMSE satisfies the goal of the project and is < 0.8649000. However, it is not perfect until we do our Matrix Factorisation. 

### Matrix Factorisation 

We will use Recosystem package to do the matrix factorisation. Firstly, we will make a train_set and test_set from edx and validation data, respectively. Also, we will clean an unused memory to make the process more quickly. 
```{r train set and test ste}
set.seed(123)
invisible(gc())
train_set <- with(edx, data_memory(user_index = userId, 
                                   item_index = movieId, 
                                   rating = rating))
test_set <- with(validation, data_memory(user_index = userId, 
                                         item_index = movieId, 
                                         rating = rating))
```
Next step is to build up a recommender system. 
```{r recommender system }
rec <- Reco()
```
Now we can tune the train set. Note that this will take time (approximately 20 minutes) to be completed. 
```{r tuning the test set }
opts <- rec$tune(train_set, opts = list(dim = c(10,20,30), 
                                        lrate = c(0.1,0.2), 
                                        costp_l1 = 0, 
                                        costq_l1 = 0, 
                                        nthread = 1, 
                                        niter = 10))
opts
```
We are then training the system. 
```{r train the system}
rec$train(train_set, opts = c(opts$min, nthread = 1, niter = 20))
```
And finally we can calculate our prediction, $\hat{Y}$, and calculate the final RMSE.
```{r calculate y_hat and RMSE}
#Calculate the prediction 
y_hat <- rec$predict(test_set, out_memory())
#Add the result into the model nresults table 
model_results <- bind_rows(model_results, 
                           data.frame(method = "Matrix Factorisation", 
                                      RMSE = RMSE(validation$rating, y_hat)))
knitr::kable(model_results)
```
Now we can look at 10 best movies and 10 movies using matrix factorisation.
```{r 10 best movies}
tibble(title = validation$title, rating = y_hat) %>%
  arrange(desc(rating)) %>% 
  group_by(title) %>%
  head(10) %>%
  knitr::kable()
```
If we return back at the start of the report we can notice that the top movie was "Pulp Fiction", however, using a matrix factorisation we defined that the top movie is "Schindlerâ€™s List". Let's look which movies are considered as the worst movies. 
```{r worst movies}
tibble(title = validation$title, rating = y_hat) %>%
  arrange(rating) %>% 
  group_by(title) %>%
  head(10) %>%
  knitr::kable()
```

# Conclusion 

Using the training set and validation set we have successfully trained several linear regression models, which we studied in the previous courses of the HarvardX Data Science programme. We identified that the linear regression model using regularised user and movie effect model and matrix factorisation gave the desired result of the RMSE < 0.8649000. The matrix factorisation produced the RMSE = 0.7823751, and we achieved this using the recosystem package and model from the (website). 

### Limitations 

Due to the big data the matrix factorisation and some machine learning algorithms are running long on the ordinary laptop and require the usage of decent amount of memory. This can cause issues for some people to test and try the code. Moreover, we have used only two parameters, however, in real-life recommendation systems use more parameters, which I have listed in the introduction section. 
Also, the algorithm uses the dataset for the existing users and films, so the addition of new users and movies will result in the alteration of the RMSE. For the model improvement in the future we should consider to implement and overcome this issue. 

# References 
1. Irizarry, R. (2021). Introduction to Data Science. Retrieved 25 October 2021, from https://rafalab.github.io/dsbook/
2. Netflix Prize - Wikipedia. (2021). Retrieved 25 October 2021, from https://en.wikipedia.org/wiki/Netflix_Prize
3. Qiu, Y. (2021). recosystem: Recommender System Using Parallel Matrix Factorization. Retrieved 25 October 2021, from https://cran.r-project.org/web/packages/recosystem/vignettes/introduction.html
4. Seif, G. (2021). An Easy Introduction to Machine Learning Recommender Systems - KDnuggets. Retrieved 25 October 2021, from https://www.kdnuggets.com/2019/09/machine-learning-recommender-systems.html





